{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: \n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза «мешка слов». Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать «мешком ингредиентов», потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные «темы». Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули *json* и *gensim*. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "*pip install gensim*\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (cuisine) и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'cuisine': u'greek', u'id': 10259, u'ingredients': [u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "print recipes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая, и целиком помещается в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'cooking spray'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.id2token[116]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print texts[0]\n",
    "print corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть две полезных переменных: *dictionary.id2token* и *dictionary.token2id*; эти словари позволяют находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. \n",
    "\n",
    "\n",
    "Затем вызовите метод модели *show_topics*, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода *show_topics* указать параметр *formatted=True*, то топы ингредиентов будет удобно выводить на печать, если *formatted=False*, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 52s, sys: 1.08 s, total: 2min 53s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "%time lda = LdaModel(corpus, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = lda.show_topics(num_topics=40, num_words=10, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics_tokens = [(topic[0], [(dictionary.id2token[int(token[0])], token[1]) for token in topic[1]]) for topic in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [(u'cooking spray', 0.08893168359335854),\n",
       "   (u'salt', 0.083023313122701475),\n",
       "   (u'garlic cloves', 0.079694482383533466),\n",
       "   (u'olive oil', 0.068056697732332513),\n",
       "   (u'chopped onion', 0.065740286303090811),\n",
       "   (u'crushed red pepper', 0.036603425389428061),\n",
       "   (u'fat free less sodium chicken broth', 0.036151588839948165),\n",
       "   (u'black pepper', 0.034352059579260526),\n",
       "   (u'ground black pepper', 0.032028828039852991),\n",
       "   (u'water', 0.032026346546356499)]),\n",
       " (1,\n",
       "  [(u'carrots', 0.084685047417615594),\n",
       "   (u'onions', 0.0594771859048897),\n",
       "   (u'sauce', 0.056696097267259209),\n",
       "   (u'cabbage', 0.056348277206384002),\n",
       "   (u'spinach', 0.046496298177981413),\n",
       "   (u'beef', 0.039387696216511205),\n",
       "   (u'low sodium chicken broth', 0.033278198173197153),\n",
       "   (u'water', 0.032572054032540064),\n",
       "   (u'firm tofu', 0.029467834271367253),\n",
       "   (u'green cabbage', 0.02771940582568299)]),\n",
       " (2,\n",
       "  [(u'cracked black pepper', 0.065793037833935572),\n",
       "   (u'dry red wine', 0.058809351108989154),\n",
       "   (u'shortening', 0.041491648463130429),\n",
       "   (u'beef broth', 0.041121673243871622),\n",
       "   (u'vegetable oil cooking spray', 0.039788950941651489),\n",
       "   (u'grape tomatoes', 0.039484338255465393),\n",
       "   (u'cilantro sprigs', 0.035205806717994434),\n",
       "   (u'french bread', 0.030809498417447789),\n",
       "   (u'dried rosemary', 0.029339305231140554),\n",
       "   (u'all-purpose flour', 0.029082580099877162)]),\n",
       " (3,\n",
       "  [(u'potatoes', 0.1326499123316614),\n",
       "   (u'oil', 0.12392896234858584),\n",
       "   (u'salt', 0.063326733043941222),\n",
       "   (u'chickpeas', 0.059179676560327278),\n",
       "   (u'onions', 0.042020178848626168),\n",
       "   (u'coriander', 0.038367186668332602),\n",
       "   (u'pepper', 0.034463196802499152),\n",
       "   (u'saffron', 0.03304843829977689),\n",
       "   (u'chopped tomatoes', 0.031199828274823347),\n",
       "   (u'vegetables', 0.026229917191349716)]),\n",
       " (4,\n",
       "  [(u'green bell pepper', 0.062137194484359851),\n",
       "   (u'garlic powder', 0.05751836529465041),\n",
       "   (u'cayenne pepper', 0.055607203040325785),\n",
       "   (u'salt', 0.053129801326957132),\n",
       "   (u'paprika', 0.04435725169468243),\n",
       "   (u'onions', 0.035222635468300581),\n",
       "   (u'dried thyme', 0.034801505725109268),\n",
       "   (u'worcestershire sauce', 0.031990203148110616),\n",
       "   (u'onion powder', 0.027267339886862418),\n",
       "   (u'ground black pepper', 0.027067277200853605)]),\n",
       " (5,\n",
       "  [(u'ground cumin', 0.076627285122494185),\n",
       "   (u'salt', 0.052261476695032068),\n",
       "   (u'ground coriander', 0.048314322271712437),\n",
       "   (u'onions', 0.03644538912594289),\n",
       "   (u'olive oil', 0.035941283188257636),\n",
       "   (u'garlic', 0.033314493875509325),\n",
       "   (u'paprika', 0.028238586829496488),\n",
       "   (u'tumeric', 0.025756401308228271),\n",
       "   (u'cayenne pepper', 0.022939776862739514),\n",
       "   (u'garlic cloves', 0.022337497196979035)]),\n",
       " (6,\n",
       "  [(u'ground cinnamon', 0.10667595663455669),\n",
       "   (u'ground nutmeg', 0.087421774887951817),\n",
       "   (u'honey', 0.056105924125548913),\n",
       "   (u'ground allspice', 0.046776482531706479),\n",
       "   (u'raisins', 0.046276683476044987),\n",
       "   (u'ground cloves', 0.045913091159994153),\n",
       "   (u'light brown sugar', 0.043664170427418485),\n",
       "   (u'ground ginger', 0.031187420812889013),\n",
       "   (u'brown sugar', 0.030182049216845884),\n",
       "   (u'margarine', 0.030117163634709392)]),\n",
       " (7,\n",
       "  [(u'zucchini', 0.084742642422514031),\n",
       "   (u'plum tomatoes', 0.080497578113583726),\n",
       "   (u'fresh basil', 0.07737071565988092),\n",
       "   (u'olive oil', 0.073934264873813715),\n",
       "   (u'eggplant', 0.046646113791840443),\n",
       "   (u'salt', 0.039214680830128586),\n",
       "   (u'grated parmesan cheese', 0.030897630465110168),\n",
       "   (u'garlic cloves', 0.029836911250445238),\n",
       "   (u'red bell pepper', 0.029530917231211366),\n",
       "   (u'spaghetti', 0.02864503120588404)]),\n",
       " (8,\n",
       "  [(u'rice', 0.087167378750825308),\n",
       "   (u'cooking oil', 0.077098782201918431),\n",
       "   (u'salt', 0.067277135535200594),\n",
       "   (u'water', 0.058749189922320158),\n",
       "   (u'basmati rice', 0.050622406492366337),\n",
       "   (u'vinegar', 0.048994075835857506),\n",
       "   (u'ginger', 0.045755197636105624),\n",
       "   (u'curry leaves', 0.035831587208418364),\n",
       "   (u'mint leaves', 0.029395533471377355),\n",
       "   (u'red cabbage', 0.023020562542491147)]),\n",
       " (9,\n",
       "  [(u'dried oregano', 0.078917014125290841),\n",
       "   (u'onions', 0.072724015772864262),\n",
       "   (u'garlic', 0.060870846457765783),\n",
       "   (u'tomato sauce', 0.057305229057996322),\n",
       "   (u'salt', 0.052576199890923207),\n",
       "   (u'ground beef', 0.050432908072482033),\n",
       "   (u'diced tomatoes', 0.049080315157360395),\n",
       "   (u'dried basil', 0.043086220699036747),\n",
       "   (u'tomato paste', 0.040347252869254051),\n",
       "   (u'olive oil', 0.034981688994508618)]),\n",
       " (10,\n",
       "  [(u'white wine', 0.049367681116827954),\n",
       "   (u'ground black pepper', 0.048029125078342998),\n",
       "   (u'butter', 0.03734028166136056),\n",
       "   (u'russet potatoes', 0.036477703219749795),\n",
       "   (u'chopped fresh chives', 0.030782680251151689),\n",
       "   (u'kosher salt', 0.029591436646871895),\n",
       "   (u'red potato', 0.027102675306152648),\n",
       "   (u'ham', 0.02662087179123895),\n",
       "   (u'large eggs', 0.025770559902268713),\n",
       "   (u'salt', 0.024067311817708412)]),\n",
       " (11,\n",
       "  [(u'jalapeno chilies', 0.066996273870029294),\n",
       "   (u'salt', 0.064211043652989838),\n",
       "   (u'avocado', 0.050618875873464794),\n",
       "   (u'lime', 0.042149718346097251),\n",
       "   (u'purple onion', 0.034953554052417721),\n",
       "   (u'garlic', 0.034417628909233194),\n",
       "   (u'olive oil', 0.032394638512492926),\n",
       "   (u'fresh cilantro', 0.031557259666404186),\n",
       "   (u'cilantro', 0.030696574173230975),\n",
       "   (u'lime juice', 0.029169836782926367)]),\n",
       " (12,\n",
       "  [(u'cucumber', 0.13387370070367383),\n",
       "   (u'lean ground beef', 0.070426345036020424),\n",
       "   (u'cider vinegar', 0.045773470475447733),\n",
       "   (u'feta cheese', 0.045341315625472341),\n",
       "   (u'lemon wedge', 0.039782988887878762),\n",
       "   (u'romaine lettuce', 0.03938062213158533),\n",
       "   (u'cream', 0.035210285179868475),\n",
       "   (u'cherry tomatoes', 0.033997167982863202),\n",
       "   (u'chili', 0.030538503372421033),\n",
       "   (u'taco seasoning mix', 0.027446808482652026)]),\n",
       " (13,\n",
       "  [(u'sour cream', 0.085502447593804945),\n",
       "   (u'salsa', 0.056321668755972193),\n",
       "   (u'shredded cheddar cheese', 0.049190995951747044),\n",
       "   (u'flour tortillas', 0.048325541653898796),\n",
       "   (u'chili powder', 0.040649866957816298),\n",
       "   (u'black beans', 0.039468024154463495),\n",
       "   (u'green onions', 0.033862702745164494),\n",
       "   (u'ground cumin', 0.031229330247281965),\n",
       "   (u'corn tortillas', 0.025747086766038263),\n",
       "   (u'cheddar cheese', 0.023999503101898981)]),\n",
       " (14,\n",
       "  [(u'white sugar', 0.11057378122584113),\n",
       "   (u'sweet potatoes', 0.085889809769788841),\n",
       "   (u'fresh mint', 0.058101769426575987),\n",
       "   (u'black peppercorns', 0.049503586868320452),\n",
       "   (u'fennel seeds', 0.045058371287366526),\n",
       "   (u'red wine', 0.0369689265867073),\n",
       "   (u'vegetable stock', 0.032155649828819757),\n",
       "   (u'sugar', 0.02423241999328667),\n",
       "   (u'maple syrup', 0.02260354568906477),\n",
       "   (u'garlic chili sauce', 0.021670741100373835)]),\n",
       " (15,\n",
       "  [(u'cold water', 0.089901875182646807),\n",
       "   (u'cinnamon sticks', 0.071898066225266399),\n",
       "   (u'boiling water', 0.056970939038014624),\n",
       "   (u'sugar', 0.04439388919230805),\n",
       "   (u'star anise', 0.041122750693504857),\n",
       "   (u'slivered almonds', 0.032580500436037219),\n",
       "   (u'cake flour', 0.029463615896518053),\n",
       "   (u'panko breadcrumbs', 0.02673348870566802),\n",
       "   (u'green olives', 0.02607419728372698),\n",
       "   (u'apple cider vinegar', 0.023535827999710102)]),\n",
       " (16,\n",
       "  [(u'extra-virgin olive oil', 0.10083323829836822),\n",
       "   (u'garlic cloves', 0.059852691103642372),\n",
       "   (u'olive oil', 0.050279471669856371),\n",
       "   (u'flat leaf parsley', 0.046381772171346272),\n",
       "   (u'freshly ground pepper', 0.039457041002068961),\n",
       "   (u'fresh lemon juice', 0.038560812772401684),\n",
       "   (u'salt', 0.038080060156889285),\n",
       "   (u'dry white wine', 0.036468942702369875),\n",
       "   (u'large garlic cloves', 0.032168171728790607),\n",
       "   (u'ground black pepper', 0.029174154327681182)]),\n",
       " (17,\n",
       "  [(u'coconut milk', 0.14039473267660527),\n",
       "   (u'parsley', 0.053520649826206232),\n",
       "   (u'thyme', 0.04787644491855552),\n",
       "   (u'chicken thighs', 0.044859599676256696),\n",
       "   (u'garlic', 0.034839085527598471),\n",
       "   (u'coconut oil', 0.033375879670636703),\n",
       "   (u'onions', 0.033202434624158568),\n",
       "   (u'Thai red curry paste', 0.024500029872723209),\n",
       "   (u'bread', 0.02438544059520378),\n",
       "   (u'salt', 0.019675543148907907)]),\n",
       " (18,\n",
       "  [(u'salt', 0.10286475889374325),\n",
       "   (u'all-purpose flour', 0.090362466014752341),\n",
       "   (u'eggs', 0.086572915929855179),\n",
       "   (u'milk', 0.08518924452520632),\n",
       "   (u'butter', 0.070028486346010096),\n",
       "   (u'baking powder', 0.054567443817826293),\n",
       "   (u'sugar', 0.049774314966074228),\n",
       "   (u'flour', 0.039811370974946109),\n",
       "   (u'baking soda', 0.034297844284951015),\n",
       "   (u'buttermilk', 0.030033979348320791)]),\n",
       " (19,\n",
       "  [(u'curry powder', 0.13496195156332091),\n",
       "   (u'frozen peas', 0.071171290698734943),\n",
       "   (u'long-grain rice', 0.064775826950889057),\n",
       "   (u'sweetened condensed milk', 0.052799270516859641),\n",
       "   (u'greek yogurt', 0.046356566864634123),\n",
       "   (u'egg whites', 0.038102212715093842),\n",
       "   (u'cauliflower', 0.03221422945034725),\n",
       "   (u'cardamom pods', 0.029779082802830429),\n",
       "   (u'black-eyed peas', 0.028101360357825313),\n",
       "   (u'ground cayenne pepper', 0.026441439466019116)]),\n",
       " (20,\n",
       "  [(u'peanut oil', 0.043991370250776277),\n",
       "   (u'ground white pepper', 0.041780605125565327),\n",
       "   (u'beansprouts', 0.035265384249864404),\n",
       "   (u'Sriracha', 0.034646633859531997),\n",
       "   (u'rice noodles', 0.031884377569569154),\n",
       "   (u'medium shrimp', 0.031803769002536127),\n",
       "   (u'peanuts', 0.029756053065311944),\n",
       "   (u'minced ginger', 0.025379689895871714),\n",
       "   (u'fish sauce', 0.025335208152624401),\n",
       "   (u'english cucumber', 0.023862186918150632)]),\n",
       " (21,\n",
       "  [(u'boneless skinless chicken breast halves', 0.11640332568244371),\n",
       "   (u'coarse salt', 0.10706265479411332),\n",
       "   (u'ground pepper', 0.067166318595237043),\n",
       "   (u'sweet onion', 0.060331028757312416),\n",
       "   (u'mayonaise', 0.055043373709271037),\n",
       "   (u'pork tenderloin', 0.0421111484123666),\n",
       "   (u'minced garlic', 0.039634875785878501),\n",
       "   (u'juice', 0.037646860212467277),\n",
       "   (u'minced onion', 0.035496123096479607),\n",
       "   (u'dried parsley', 0.031200914254888953)]),\n",
       " (22,\n",
       "  [(u'diced onions', 0.079666106233620484),\n",
       "   (u'lettuce', 0.053874361311095048),\n",
       "   (u'self rising flour', 0.053581399591004601),\n",
       "   (u'provolone cheese', 0.04767666800158088),\n",
       "   (u'iceberg lettuce', 0.032195728798238232),\n",
       "   (u'frozen pastry puff sheets', 0.028023578678438056),\n",
       "   (u'romano cheese', 0.026366207094139442),\n",
       "   (u'semi-sweet chocolate morsels', 0.024739932878896833),\n",
       "   (u'shredded cheese', 0.024250997391988646),\n",
       "   (u'reduced-fat sour cream', 0.023994981899309376)]),\n",
       " (23,\n",
       "  [(u'lemon juice', 0.1859025967625941),\n",
       "   (u'dijon mustard', 0.092396860942664361),\n",
       "   (u'creole seasoning', 0.050843831695975908),\n",
       "   (u'white pepper', 0.040348907919114795),\n",
       "   (u'fresh orange juice', 0.038844295144291045),\n",
       "   (u'nutmeg', 0.038060844779090865),\n",
       "   (u'kale', 0.028640742093208438),\n",
       "   (u'mayonaise', 0.028356509516377686),\n",
       "   (u'salmon fillets', 0.02752542476035702),\n",
       "   (u'cream cheese, soften', 0.027435155618422604)]),\n",
       " (24,\n",
       "  [(u'sugar', 0.082453218520814012),\n",
       "   (u'whipping cream', 0.072329870172957264),\n",
       "   (u'orange juice', 0.057250463780346775),\n",
       "   (u'hot water', 0.053546189662835815),\n",
       "   (u'chopped garlic', 0.04972179931298535),\n",
       "   (u'orange', 0.049390725220929042),\n",
       "   (u'bananas', 0.03286020336946778),\n",
       "   (u'bread flour', 0.029905571050704398),\n",
       "   (u'water', 0.028949545123101886),\n",
       "   (u'brandy', 0.028938175672233449)]),\n",
       " (25,\n",
       "  [(u'salt', 0.065871753443314057),\n",
       "   (u'cumin seed', 0.06278425263867464),\n",
       "   (u'onions', 0.054114490241465668),\n",
       "   (u'ground turmeric', 0.044684336544209523),\n",
       "   (u'garam masala', 0.041087806617558217),\n",
       "   (u'green chilies', 0.040652071900723626),\n",
       "   (u'clove', 0.040140537637780783),\n",
       "   (u'chili powder', 0.031494442303467207),\n",
       "   (u'tomatoes', 0.031275683612755067),\n",
       "   (u'oil', 0.02831211985150852)]),\n",
       " (26,\n",
       "  [(u'fish sauce', 0.08420864192503856),\n",
       "   (u'white vinegar', 0.046084312302042303),\n",
       "   (u'sugar', 0.041848864506921282),\n",
       "   (u'garlic', 0.036764958396804451),\n",
       "   (u'lime juice', 0.035671568932308134),\n",
       "   (u'vegetable oil', 0.035486682652469265),\n",
       "   (u'shallots', 0.033799280291788934),\n",
       "   (u'water', 0.030368191568572948),\n",
       "   (u'lemongrass', 0.030267956649511311),\n",
       "   (u'red chili peppers', 0.027278543818785077)]),\n",
       " (27,\n",
       "  [(u'grated parmesan cheese', 0.10281313277605157),\n",
       "   (u'warm water', 0.056023143719680382),\n",
       "   (u'salt', 0.055852693884866259),\n",
       "   (u'shredded mozzarella cheese', 0.0457192036500828),\n",
       "   (u'olive oil', 0.043353303369085848),\n",
       "   (u'ricotta cheese', 0.038497923750263743),\n",
       "   (u'active dry yeast', 0.037084913718776168),\n",
       "   (u'mozzarella cheese', 0.035547862325468957),\n",
       "   (u'butter', 0.032079773850890059),\n",
       "   (u'italian seasoning', 0.031181273689060866)]),\n",
       " (28,\n",
       "  [(u'shrimp', 0.19921560106740371),\n",
       "   (u'pork', 0.056731929515849489),\n",
       "   (u'baby spinach', 0.055199861626734868),\n",
       "   (u'jasmine rice', 0.034041225114900805),\n",
       "   (u'unsweetened coconut milk', 0.033342232538592427),\n",
       "   (u'fresh tomatoes', 0.0326988589456116),\n",
       "   (u'noodles', 0.032239892816296724),\n",
       "   (u'black mustard seeds', 0.031090906246051951),\n",
       "   (u'sausage casings', 0.028473920185160453),\n",
       "   (u'sea scallops', 0.024708106354625559)]),\n",
       " (29,\n",
       "  [(u'mushrooms', 0.13370062600240296),\n",
       "   (u'white wine vinegar', 0.082420861230125972),\n",
       "   (u'shallots', 0.047723143819926941),\n",
       "   (u'boneless chicken breast', 0.041587891954967829),\n",
       "   (u'olive oil', 0.033856497284732848),\n",
       "   (u'chopped fresh sage', 0.032934209580945624),\n",
       "   (u'butter', 0.027348052639168331),\n",
       "   (u'chorizo sausage', 0.025859993446401663),\n",
       "   (u'blanched almonds', 0.025701974236252426),\n",
       "   (u'chicken drumsticks', 0.024006902993904778)]),\n",
       " (30,\n",
       "  [(u'large eggs', 0.089062231258919419),\n",
       "   (u'unsalted butter', 0.087749122814195279),\n",
       "   (u'sugar', 0.066706636124197249),\n",
       "   (u'salt', 0.057487558616575625),\n",
       "   (u'all-purpose flour', 0.054236899435070249),\n",
       "   (u'heavy cream', 0.050370914632283124),\n",
       "   (u'whole milk', 0.038227090700873836),\n",
       "   (u'vanilla extract', 0.033379734684661419),\n",
       "   (u'granulated sugar', 0.03289547370145933),\n",
       "   (u'large egg yolks', 0.029049410950041512)]),\n",
       " (31,\n",
       "  [(u'salt', 0.071339350801740822),\n",
       "   (u'ground red pepper', 0.063071473248333829),\n",
       "   (u'water', 0.052144710591120864),\n",
       "   (u'finely chopped onion', 0.052130563741673193),\n",
       "   (u'chopped celery', 0.045768566719169859),\n",
       "   (u'green beans', 0.0317593412063387),\n",
       "   (u'hot pepper sauce', 0.031215682847699162),\n",
       "   (u'long grain white rice', 0.031113719683935174),\n",
       "   (u'chopped onion', 0.030216000571252819),\n",
       "   (u'chopped green bell pepper', 0.028476312336976325)]),\n",
       " (32,\n",
       "  [(u'water', 0.06287781815156801),\n",
       "   (u'fine sea salt', 0.059885257642065294),\n",
       "   (u'lemon zest', 0.050299856797266271),\n",
       "   (u'fresh spinach', 0.048544649363033189),\n",
       "   (u'yukon gold potatoes', 0.041418503772449503),\n",
       "   (u'sesame seeds', 0.035932093547977502),\n",
       "   (u'collard greens', 0.033622654691453195),\n",
       "   (u'parmigiano reggiano cheese', 0.031740243889248634),\n",
       "   (u'rice flour', 0.03088222539595115),\n",
       "   (u'tofu', 0.029141558274488503)]),\n",
       " (33,\n",
       "  [(u'balsamic vinegar', 0.13345457601766372),\n",
       "   (u'dark soy sauce', 0.070321020054338879),\n",
       "   (u'chopped fresh mint', 0.06636700355109669),\n",
       "   (u'baguette', 0.06290110355131559),\n",
       "   (u'broccoli', 0.050702552990296003),\n",
       "   (u'penne', 0.031336646581226472),\n",
       "   (u'mint', 0.031093589359164689),\n",
       "   (u'tequila', 0.028204513804840153),\n",
       "   (u'red kidney beans', 0.01929381323437588),\n",
       "   (u'arugula', 0.018389991254781399)]),\n",
       " (34,\n",
       "  [(u'onions', 0.089085707471460565),\n",
       "   (u'salt', 0.073919225951533787),\n",
       "   (u'garlic', 0.059243801214696606),\n",
       "   (u'olive oil', 0.048618182336489221),\n",
       "   (u'bay leaves', 0.041403856253007014),\n",
       "   (u'ground black pepper', 0.040927384955912617),\n",
       "   (u'chicken stock', 0.037726916953243671),\n",
       "   (u'pepper', 0.037275092357760164),\n",
       "   (u'carrots', 0.036579406224027111),\n",
       "   (u'chicken', 0.031641802885223586)]),\n",
       " (35,\n",
       "  [(u'soy sauce', 0.097333460210104458),\n",
       "   (u'sesame oil', 0.051797356283510683),\n",
       "   (u'sugar', 0.042182965449773215),\n",
       "   (u'corn starch', 0.041984278268559438),\n",
       "   (u'garlic', 0.039126762140688998),\n",
       "   (u'green onions', 0.035174153493348737),\n",
       "   (u'scallions', 0.034526422388543032),\n",
       "   (u'rice vinegar', 0.034279495110043412),\n",
       "   (u'salt', 0.028955740531032895),\n",
       "   (u'water', 0.028487727902946732)]),\n",
       " (36,\n",
       "  [(u'cheese', 0.10850055118031686),\n",
       "   (u'garlic salt', 0.064459690669521771),\n",
       "   (u'rice wine', 0.060875479422394414),\n",
       "   (u'chives', 0.057857051533694213),\n",
       "   (u'chicken breast halves', 0.043411401321535384),\n",
       "   (u'shredded sharp cheddar cheese', 0.040932366001012577),\n",
       "   (u'roasted peanuts', 0.040240696971079078),\n",
       "   (u'Mexican cheese blend', 0.038537740457462208),\n",
       "   (u'non-fat sour cream', 0.037499554691035122),\n",
       "   (u'dashi', 0.033584279538834229)]),\n",
       " (37,\n",
       "  [(u'chicken broth', 0.17999160062170214),\n",
       "   (u'chicken breasts', 0.10057712507317254),\n",
       "   (u'onions', 0.061890531149927409),\n",
       "   (u'crushed red pepper flakes', 0.053363655286096531),\n",
       "   (u'garlic', 0.053173533714141658),\n",
       "   (u'pepper', 0.040642865177376947),\n",
       "   (u'chopped parsley', 0.037946240223094445),\n",
       "   (u'salt', 0.034784082726492804),\n",
       "   (u'olive oil', 0.033766631399446981),\n",
       "   (u'bay leaf', 0.025032033012338407)]),\n",
       " (38,\n",
       "  [(u'olive oil', 0.063505123706221175),\n",
       "   (u'red wine vinegar', 0.060345068935401015),\n",
       "   (u'salt', 0.054207015287186126),\n",
       "   (u'parmesan cheese', 0.045452526393073997),\n",
       "   (u'garlic', 0.040618271781896108),\n",
       "   (u'fresh basil leaves', 0.040307700322139109),\n",
       "   (u'extra-virgin olive oil', 0.036865114941628675),\n",
       "   (u'pepper', 0.030579913039912882),\n",
       "   (u'ground black pepper', 0.029771155477254372),\n",
       "   (u'tomatoes', 0.029571536712105082)]),\n",
       " (39,\n",
       "  [(u'canola oil', 0.10058287392851892),\n",
       "   (u'fresh lime juice', 0.06616517293397399),\n",
       "   (u'chopped cilantro fresh', 0.062742696003273576),\n",
       "   (u'kosher salt', 0.058468985000598432),\n",
       "   (u'garlic cloves', 0.053626273422525607),\n",
       "   (u'peeled fresh ginger', 0.03449569478587363),\n",
       "   (u'chiles', 0.030200642640448895),\n",
       "   (u'vegetable oil', 0.029459568934012251),\n",
       "   (u'serrano chile', 0.02766543733693199),\n",
       "   (u'boneless chicken skinless thigh', 0.025502752658135532)])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "flat_list = list(chain(*[[token[0] for token in topic[1]] for topic in topics_tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ingredients = \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\"\n",
    "save_answers1(*[flat_list.count(i) for i in ingredients])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами — фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная *dfs* — это словарь, ключами которого являются id токена, а элементами — число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря *filter_tokens*, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after — размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after — суммарное количество ингредиентов в корпусе (иными словами, сумма длин всех документов коллекции) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_size_before = len(dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = [k for k in dictionary2.dfs if dictionary2.dfs[k] > 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary2.filter_tokens(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_size_after = len(dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6714, 6702, 12)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size_before, dict_size_after, len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus2 = [dictionary2.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def corpus_size(corpus):\n",
    "    size = 0\n",
    "    for sentence in corpus:\n",
    "        for word, count in sentence:\n",
    "            size += count\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428275, 343686)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_size(corpus), corpus_size(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_answers2(dict_size_before, dict_size_after, corpus_size(corpus),  corpus_size(corpus2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictionary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом *top_topics* модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 32s, sys: 1.11 s, total: 2min 33s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "%time lda2 = LdaModel(corpus2, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coh = lda.top_topics(corpus)\n",
    "coh2 = lda2.top_topics(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_coh = 0\n",
    "cnt = 0\n",
    "for topic, coherence in coh:\n",
    "    cnt += 1\n",
    "    avg_coh += coherence\n",
    "avg_coh /= cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "avg_coh2 = 0\n",
    "for topic, coherence in coh2:\n",
    "    cnt += 1\n",
    "    avg_coh2 += coherence\n",
    "avg_coh2 /= cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-627.26151033997087, -682.55267319317477)\n"
     ]
    }
   ],
   "source": [
    "print(avg_coh, avg_coh2)\n",
    "save_answers3(avg_coh, avg_coh2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом *get_document_topics* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0.12812499999999988),\n",
       " (15, 0.32363797161919383),\n",
       " (22, 0.27663627763376558),\n",
       " (37, 0.15910075074703992)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.get_document_topics(corpus2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной *.alpha* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,\n",
       "        0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025,  0.025])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda2.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте про фиксацию seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром *minimum_probability=0.01* и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 59s, sys: 4.13 s, total: 7min 3s\n",
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "%time lda3 = LdaModel(corpus2, num_topics=40, alpha=1, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.040816326530612242),\n",
       " (1, 0.020408163265306121),\n",
       " (2, 0.020408163265306121),\n",
       " (3, 0.040816326530612242),\n",
       " (4, 0.020408163265306121),\n",
       " (5, 0.020408163265306121),\n",
       " (6, 0.020408163265306121),\n",
       " (7, 0.020408163265306121),\n",
       " (8, 0.020408163265306121),\n",
       " (9, 0.040816326530612242),\n",
       " (10, 0.020408163265306121),\n",
       " (11, 0.040816326530612242),\n",
       " (12, 0.020408163265306121),\n",
       " (13, 0.020408163265306121),\n",
       " (14, 0.020408163265306121),\n",
       " (15, 0.020408163265306121),\n",
       " (16, 0.020408163265306121),\n",
       " (17, 0.020408163265306121),\n",
       " (18, 0.020408163265306121),\n",
       " (19, 0.020408163265306121),\n",
       " (20, 0.020408163265306121),\n",
       " (21, 0.040816326530612242),\n",
       " (22, 0.020408163265306121),\n",
       " (23, 0.040816326530612242),\n",
       " (24, 0.020408163265306121),\n",
       " (25, 0.020408163265306121),\n",
       " (26, 0.020408163265306121),\n",
       " (27, 0.020408163265306121),\n",
       " (28, 0.040816326530612235),\n",
       " (29, 0.020408163265306121),\n",
       " (30, 0.020408163265306121),\n",
       " (31, 0.040816326530612242),\n",
       " (32, 0.020408163265306121),\n",
       " (33, 0.020408163265306121),\n",
       " (34, 0.020408163265306121),\n",
       " (35, 0.020408163265306121),\n",
       " (36, 0.040816326530612242),\n",
       " (37, 0.020408163265306121),\n",
       " (38, 0.020408163265306121),\n",
       " (39, 0.020408163265306121)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda3.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sz3 = 0\n",
    "for text in corpus2:\n",
    "    sz3 += len(lda3.get_document_topics(text, minimum_probability=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sz2 = 0\n",
    "for text in corpus2:\n",
    "    sz2 += len(lda2.get_document_topics(text, minimum_probability=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_answers4(sz2, sz3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр __alpha__ влияет на разреженность распределений тем в документах. Аналогично гиперпараметр __eta__ влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда, распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for text in corpus2:\n",
    "    feats = [0] * 40\n",
    "    for topic, value in lda2.get_document_topics(text):\n",
    "        feats[topic] = value\n",
    "    X.append(feats)\n",
    "X = numpy.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = [recipe[u'cuisine'] for recipe in recipes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, n_jobs=4)\n",
    "score = cross_val_score(forest, X, y, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = numpy.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_answers5(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10–15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA — вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(0, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6263\n",
      "1184\n",
      "269\n",
      "5575\n",
      "713\n",
      "11\n",
      "5333\n",
      "269\n",
      "6064\n",
      "6154\n"
     ]
    }
   ],
   "source": [
    "generate_recipe(lda2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу $A$ размера темы $x$ кухни, ее элементы $a_{tc}$ — суммы $p(t|d)$ по всем документам $d$, которые отнесены к кухне $c$. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу $A$. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/astepanov/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/Users/astepanov/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу\n",
    "plot_matrix(compute_topic_cuisine_matrix(lda2, corpus2, recipes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
